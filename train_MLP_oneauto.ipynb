{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-364.1775   -975.4356   6021.122    -109.1984   -954.0909   6099.669\n",
      "  -508.9153   -730.9489   5921.708       6.785923 -680.884    6149.784\n",
      "  -557.0898   -488.4602   5995.181     -46.69554  -470.2704   6288.714\n",
      "  -372.7751   -575.7365   5872.574    -103.1269   -597.285    5963.012\n",
      "  -446.7088   -132.9091   6060.143    -170.6657   -143.0198   6123.739\n",
      "  -456.9418    323.8216   6125.481    -171.2247    317.4601   6093.172   ]]\n",
      "[[  90.01911  -712.6233   3312.449      65.28832  -637.2011   3006.589\n",
      "    12.47191  -532.5627   3516.78        3.935964 -372.9722   2925.318\n",
      "   171.4691   -390.2531   3389.79      176.4971   -232.0712   3034.999\n",
      "    34.38879  -260.741    3373.961     -61.70858  -226.4938   3117.111\n",
      "    85.31891   195.8902   3421.741     -87.43157   221.6817   3226.042\n",
      "    -5.04759   645.9555   3454.621    -365.6985    473.6731   3492.263   ]]\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd \n",
    "import argparse\n",
    "import random\n",
    "from scipy.spatial.transform import Rotation\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "  tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "# Imposta il seed per numpy\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "custom = True\n",
    "\n",
    "_size = \"500\"\n",
    "dataset = \"h36m\"\n",
    "_type = \"3D\"\n",
    "ceil = 10 \n",
    "dim = 2\n",
    "method = \"gt\"\n",
    "name = \"completion_murino_\"+_type+\"_\"+dataset+\"_\" + method +\"_mask\"+str(ceil)+\"_norot\" # 0.0411 with +30*\n",
    "\n",
    "\n",
    "\n",
    "def random_rotation_2d():    \n",
    "    # Genera un angolo casuale per la rotazione in radianti\n",
    "    #angle = np.random.uniform(0, 2 * np.pi)\n",
    "    #angle = np.random.uniform(-np.pi/6,np.pi/6)\n",
    "    angle=0\n",
    "    # Crea la matrice di rotazione 2D\n",
    "    rotation_matrix = np.array([[np.cos(angle), -np.sin(angle)],\n",
    "                                [np.sin(angle), np.cos(angle)]])\n",
    "\n",
    "    return rotation_matrix\n",
    "\n",
    "def random_rotation_3d():    \n",
    "    # Genera una rotazione casuale tramite l'uso della libreria `scipy`\n",
    "    rotation = Rotation.from_euler('xyz', np.random.rand(3), degrees=False)\n",
    "    \n",
    "    # Estrai la matrice di rotazione dalla rotazione\n",
    "    rotation_matrix = rotation.as_matrix()\n",
    "    \n",
    "    return rotation_matrix\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_name = '../models/' + name + '.h5'\n",
    "input_path = \"../local_dataset/training/completion/\"+_type+\"/\"\n",
    "\n",
    "if method is not None:\n",
    "    X_train = np.load(os.path.join(input_path,\"X_train_\" + dataset + \"_\" +  _size +  \"_minmax.npy\")).swapaxes(1,2)\n",
    "    X_val = np.load(os.path.join(input_path,\"X_val_\" + dataset + \"_\" +  _size +  \"_minmax.npy\")).swapaxes(1,2)\n",
    "else:\n",
    "    X_train = np.load(os.path.join(input_path,\"X_train_\" + dataset + \"_\" + method + \"_\" + _size +  \"_minmax.npy\")).swapaxes(1,2)\n",
    "    X_val = np.load(os.path.join(input_path,\"X_val_\" + dataset + \"_\" + method + \"_\" + _size +  \"_minmax.npy\")).swapaxes(1,2)\n",
    "\n",
    "\n",
    "if custom:\n",
    "    X_train = np.load(\"/home/emartini/nas/MAEVE/HUMAN_MODEL/dataset/training_FLK2/h36m_cameraview_3D/X_train_1000.npy\")\n",
    "    X_val = np.load(\"/home/emartini/nas/MAEVE/HUMAN_MODEL/dataset/training_FLK2/h36m_cameraview_3D/X_val_1000.npy\")\n",
    "    model_name = \"tmp/MLP_bio_h36m_cameraview_3D_absolute_onehot.h5\"\n",
    "    dim = 3\n",
    "\n",
    "#X_val = np.load(os.path.join(input_path,\"X_val_aist_\" +  _size +  \"_minmax.npy\")).swapaxes(1,2)\n",
    "#X_test = np.load(os.path.join(input_path,\"X_test_\" + dataset + \"_\" +  _size +  \".npy\")).swapaxes(1,2)\n",
    "\n",
    "#X_train = X_train.swapaxes(1,2)\n",
    "#X_val = X_val.swapaxes(1,2)\n",
    "\n",
    "print(X_train[0,:,:])\n",
    "print(X_val[0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoints = int(X_train.shape[2]/dim) \n",
    "\n",
    "# X_train = X_train[:100,:,:]\n",
    "# X_val = X_val[:100,:,:]\n",
    "\n",
    "X_train_enhanced = np.repeat(X_train,1,axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_bio_root_absolute(dataset):\n",
    "    from Skeleton import Skeleton,ConstrainedSkeleton\n",
    "    s12 = Skeleton('BODY12.xml')\n",
    "    s15 = ConstrainedSkeleton('BODY15_constrained.xml')\n",
    "    # Normalization using Biomecanichal model\n",
    "    labels = ['LShoulder','RShoulder','LElbow','RElbow','LWrist','RWrist','LHip','RHip','LKnee','RKnee','LAnkle','RAnkle']\n",
    "    \n",
    "    for j in range(dataset.shape[0]):\n",
    "        x = dataset[j,:,:].reshape(-1,3)\n",
    "        s12.load_from_numpy(x,labels)\n",
    "        s15.load_from_BODY12(s12)\n",
    "        h = s15.estimate_height(False)\n",
    "        root = s15.to_numpy([\"Root\"])\n",
    "        x = (x-root)/h\n",
    "        dataset[j,:,:] = x.ravel()\n",
    "\n",
    "normalize_bio_root_absolute(X_train_enhanced)\n",
    "normalize_bio_root_absolute(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masking\n",
      "[[[        nan         nan         nan ...         nan         nan\n",
      "    1.        ]]\n",
      "\n",
      " [[        nan         nan         nan ...         nan         nan\n",
      "    1.        ]]\n",
      "\n",
      " [[        nan         nan         nan ...         nan         nan\n",
      "    1.        ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.08766368 -0.13355102 -0.0016917  ...         nan         nan\n",
      "    1.        ]]\n",
      "\n",
      " [[-0.05917127 -0.11206585 -0.09970918 ...  0.63427097  0.28789654\n",
      "    0.        ]]\n",
      "\n",
      " [[ 0.0792622  -0.12775844 -0.02317264 ...  0.6958241   0.09664778\n",
      "    0.        ]]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Masking\")\n",
    "y_train = X_train_enhanced.copy()\n",
    "X_train_enhanced_oneauto = np.zeros( (X_train_enhanced.shape[0], X_train_enhanced.shape[1], keypoints*(dim+1)) )\n",
    "for r in range(X_train_enhanced.shape[0]):      \n",
    "    kps_to_mask = np.random.choice(list(range(keypoints)),np.random.randint(low=1,high=ceil+1),replace=False)\n",
    "    for j in kps_to_mask:\n",
    "        X_train_enhanced[r,0,dim*j:dim*j+dim] = np.nan\n",
    "    skeleton = X_train_enhanced[r,0,:].reshape(-1,3)\n",
    "    skeleton = np.insert(skeleton, 3, values=np.where(np.isnan(skeleton[:,0]), 1, 0), axis=1)\n",
    "    X_train_enhanced_oneauto[r,0,:] = skeleton.ravel()\n",
    "    \n",
    "X_train = X_train_enhanced_oneauto.copy()\n",
    "# print(X_train)\n",
    "\n",
    "y_val = X_val.copy()\n",
    "X_val_enhanced_oneauto = np.zeros( (X_val.shape[0], X_val.shape[1], keypoints*(dim+1)) )\n",
    "for r in range(X_val.shape[0]):      \n",
    "        kps_to_mask = np.random.choice(list(range(keypoints)),np.random.randint(low=1,high=ceil+1),replace=False)\n",
    "        for j in kps_to_mask:\n",
    "            X_val[r,0,dim*j:dim*j+dim] = np.nan\n",
    "        skeleton = X_val[r,0,:].reshape(-1,3)\n",
    "        skeleton = np.insert(skeleton, 3, values=np.where(np.isnan(skeleton[:,0]), 1, 0), axis=1)\n",
    "        X_val_enhanced_oneauto[r,0,:] = skeleton.ravel()\n",
    "X_val = X_val_enhanced_oneauto.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mlp_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 48)]              0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            multiple                  6272      \n",
      "                                                                 \n",
      " dense_17 (Dense)            multiple                  33024     \n",
      "                                                                 \n",
      " dense_18 (Dense)            multiple                  32896     \n",
      "                                                                 \n",
      " dense_19 (Dense)            multiple                  4644      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 76836 (300.14 KB)\n",
      "Trainable params: 76836 (300.14 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0034 - mae: 0.0375 - val_loss: 0.0024 - val_mae: 0.0309\n",
      "Epoch 2/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0023 - mae: 0.0290 - val_loss: 0.0022 - val_mae: 0.0283\n",
      "Epoch 3/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0021 - mae: 0.0275 - val_loss: 0.0021 - val_mae: 0.0273\n",
      "Epoch 4/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0020 - mae: 0.0267 - val_loss: 0.0021 - val_mae: 0.0268\n",
      "Epoch 5/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0020 - mae: 0.0261 - val_loss: 0.0020 - val_mae: 0.0274\n",
      "Epoch 6/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0019 - mae: 0.0257 - val_loss: 0.0019 - val_mae: 0.0255\n",
      "Epoch 7/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0019 - mae: 0.0254 - val_loss: 0.0019 - val_mae: 0.0258\n",
      "Epoch 8/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0019 - mae: 0.0251 - val_loss: 0.0019 - val_mae: 0.0251\n",
      "Epoch 9/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0019 - mae: 0.0249 - val_loss: 0.0018 - val_mae: 0.0249\n",
      "Epoch 10/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0018 - mae: 0.0247 - val_loss: 0.0018 - val_mae: 0.0246\n",
      "Epoch 11/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0018 - mae: 0.0246 - val_loss: 0.0018 - val_mae: 0.0239\n",
      "Epoch 12/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0018 - mae: 0.0244 - val_loss: 0.0018 - val_mae: 0.0242\n",
      "Epoch 13/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0018 - mae: 0.0243 - val_loss: 0.0018 - val_mae: 0.0247\n",
      "Epoch 14/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0018 - mae: 0.0242 - val_loss: 0.0018 - val_mae: 0.0242\n",
      "Epoch 15/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0018 - mae: 0.0241 - val_loss: 0.0018 - val_mae: 0.0241\n",
      "Epoch 16/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0018 - mae: 0.0240 - val_loss: 0.0017 - val_mae: 0.0236\n",
      "Epoch 17/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0018 - mae: 0.0239 - val_loss: 0.0018 - val_mae: 0.0239\n",
      "Epoch 18/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0017 - mae: 0.0238 - val_loss: 0.0018 - val_mae: 0.0245\n",
      "Epoch 19/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0017 - mae: 0.0237 - val_loss: 0.0018 - val_mae: 0.0239\n",
      "Epoch 20/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0017 - mae: 0.0236 - val_loss: 0.0018 - val_mae: 0.0238\n",
      "Epoch 21/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0017 - mae: 0.0236 - val_loss: 0.0017 - val_mae: 0.0238\n",
      "Epoch 22/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0017 - mae: 0.0235 - val_loss: 0.0017 - val_mae: 0.0233\n",
      "Epoch 23/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0017 - mae: 0.0234 - val_loss: 0.0017 - val_mae: 0.0236\n",
      "Epoch 24/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0017 - mae: 0.0234 - val_loss: 0.0017 - val_mae: 0.0233\n",
      "Epoch 25/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0017 - mae: 0.0233 - val_loss: 0.0017 - val_mae: 0.0235\n",
      "Epoch 26/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0017 - mae: 0.0233 - val_loss: 0.0017 - val_mae: 0.0232\n",
      "Epoch 27/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0017 - mae: 0.0233 - val_loss: 0.0017 - val_mae: 0.0230\n",
      "Epoch 28/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0017 - mae: 0.0232 - val_loss: 0.0017 - val_mae: 0.0236\n",
      "Epoch 29/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0017 - mae: 0.0231 - val_loss: 0.0017 - val_mae: 0.0230\n",
      "Epoch 30/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0017 - mae: 0.0231 - val_loss: 0.0017 - val_mae: 0.0233\n",
      "Epoch 31/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0017 - mae: 0.0231 - val_loss: 0.0017 - val_mae: 0.0231\n",
      "Epoch 32/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0017 - mae: 0.0230 - val_loss: 0.0017 - val_mae: 0.0231\n",
      "Epoch 33/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0017 - mae: 0.0230 - val_loss: 0.0017 - val_mae: 0.0230\n",
      "Epoch 34/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0017 - mae: 0.0230 - val_loss: 0.0017 - val_mae: 0.0228\n",
      "Epoch 35/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0017 - mae: 0.0229 - val_loss: 0.0017 - val_mae: 0.0234\n",
      "Epoch 36/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0017 - mae: 0.0229 - val_loss: 0.0017 - val_mae: 0.0226\n",
      "Epoch 37/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0017 - mae: 0.0228 - val_loss: 0.0017 - val_mae: 0.0234\n",
      "Epoch 38/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0016 - mae: 0.0228 - val_loss: 0.0017 - val_mae: 0.0228\n",
      "Epoch 39/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0016 - mae: 0.0228 - val_loss: 0.0017 - val_mae: 0.0229\n",
      "Epoch 40/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0016 - mae: 0.0227 - val_loss: 0.0017 - val_mae: 0.0227\n",
      "Epoch 41/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0016 - mae: 0.0227 - val_loss: 0.0017 - val_mae: 0.0234\n",
      "Epoch 42/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0016 - mae: 0.0227 - val_loss: 0.0017 - val_mae: 0.0231\n",
      "Epoch 43/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0016 - mae: 0.0227 - val_loss: 0.0017 - val_mae: 0.0231\n",
      "Epoch 44/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0016 - mae: 0.0227 - val_loss: 0.0017 - val_mae: 0.0226\n",
      "Epoch 45/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0016 - mae: 0.0226 - val_loss: 0.0017 - val_mae: 0.0234\n",
      "Epoch 46/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0016 - mae: 0.0226 - val_loss: 0.0017 - val_mae: 0.0228\n",
      "Epoch 47/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0016 - mae: 0.0226 - val_loss: 0.0016 - val_mae: 0.0226\n",
      "Epoch 48/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0016 - mae: 0.0225 - val_loss: 0.0017 - val_mae: 0.0228\n",
      "Epoch 49/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0016 - mae: 0.0225 - val_loss: 0.0017 - val_mae: 0.0226\n",
      "Epoch 50/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0016 - mae: 0.0225 - val_loss: 0.0016 - val_mae: 0.0223\n",
      "Epoch 51/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0016 - mae: 0.0225 - val_loss: 0.0016 - val_mae: 0.0226\n",
      "Epoch 52/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0016 - mae: 0.0225 - val_loss: 0.0017 - val_mae: 0.0229\n",
      "Epoch 53/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0016 - mae: 0.0224 - val_loss: 0.0016 - val_mae: 0.0225\n",
      "Epoch 54/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0016 - mae: 0.0224 - val_loss: 0.0017 - val_mae: 0.0227\n",
      "Epoch 55/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0016 - mae: 0.0224 - val_loss: 0.0016 - val_mae: 0.0223\n",
      "Epoch 56/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0016 - mae: 0.0224 - val_loss: 0.0017 - val_mae: 0.0227\n",
      "Epoch 57/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0016 - mae: 0.0224 - val_loss: 0.0016 - val_mae: 0.0224\n",
      "Epoch 58/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0016 - mae: 0.0223 - val_loss: 0.0017 - val_mae: 0.0226\n",
      "Epoch 59/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0016 - mae: 0.0223 - val_loss: 0.0016 - val_mae: 0.0225\n",
      "Epoch 60/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0016 - mae: 0.0223 - val_loss: 0.0017 - val_mae: 0.0228\n",
      "Epoch 61/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0016 - mae: 0.0223 - val_loss: 0.0017 - val_mae: 0.0227\n",
      "Epoch 62/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0016 - mae: 0.0223 - val_loss: 0.0017 - val_mae: 0.0226\n",
      "Epoch 63/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0016 - mae: 0.0222 - val_loss: 0.0016 - val_mae: 0.0223\n",
      "Epoch 64/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0016 - mae: 0.0222 - val_loss: 0.0016 - val_mae: 0.0222\n",
      "Epoch 65/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0016 - mae: 0.0222 - val_loss: 0.0016 - val_mae: 0.0223\n",
      "Epoch 66/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0016 - mae: 0.0222 - val_loss: 0.0017 - val_mae: 0.0226\n",
      "Epoch 67/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0016 - mae: 0.0222 - val_loss: 0.0016 - val_mae: 0.0221\n",
      "Epoch 68/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0016 - mae: 0.0222 - val_loss: 0.0017 - val_mae: 0.0226\n",
      "Epoch 69/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0016 - mae: 0.0222 - val_loss: 0.0016 - val_mae: 0.0224\n",
      "Epoch 70/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0016 - mae: 0.0222 - val_loss: 0.0016 - val_mae: 0.0224\n",
      "Epoch 71/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0016 - mae: 0.0221 - val_loss: 0.0016 - val_mae: 0.0220\n",
      "Epoch 72/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0016 - mae: 0.0221 - val_loss: 0.0016 - val_mae: 0.0223\n",
      "Epoch 73/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0016 - mae: 0.0221 - val_loss: 0.0016 - val_mae: 0.0222\n",
      "Epoch 74/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0016 - mae: 0.0221 - val_loss: 0.0016 - val_mae: 0.0222\n",
      "Epoch 75/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0016 - mae: 0.0221 - val_loss: 0.0016 - val_mae: 0.0222\n",
      "Epoch 76/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0016 - mae: 0.0221 - val_loss: 0.0016 - val_mae: 0.0221\n",
      "Epoch 77/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0016 - mae: 0.0221 - val_loss: 0.0016 - val_mae: 0.0220\n",
      "Epoch 78/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0016 - mae: 0.0220 - val_loss: 0.0016 - val_mae: 0.0223\n",
      "Epoch 79/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0016 - mae: 0.0220 - val_loss: 0.0016 - val_mae: 0.0222\n",
      "Epoch 80/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0016 - mae: 0.0220 - val_loss: 0.0017 - val_mae: 0.0227\n",
      "Epoch 81/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0016 - mae: 0.0220 - val_loss: 0.0016 - val_mae: 0.0220\n",
      "Epoch 82/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0016 - mae: 0.0220 - val_loss: 0.0016 - val_mae: 0.0223\n",
      "Epoch 83/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0016 - mae: 0.0220 - val_loss: 0.0016 - val_mae: 0.0222\n",
      "Epoch 84/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0016 - mae: 0.0220 - val_loss: 0.0016 - val_mae: 0.0223\n",
      "Epoch 85/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0016 - mae: 0.0220 - val_loss: 0.0016 - val_mae: 0.0220\n",
      "Epoch 86/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0016 - mae: 0.0220 - val_loss: 0.0016 - val_mae: 0.0219\n",
      "Epoch 87/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0016 - mae: 0.0220 - val_loss: 0.0016 - val_mae: 0.0220\n",
      "Epoch 88/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0016 - mae: 0.0219 - val_loss: 0.0016 - val_mae: 0.0224\n",
      "Epoch 89/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0016 - mae: 0.0219 - val_loss: 0.0016 - val_mae: 0.0219\n",
      "Epoch 90/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0016 - mae: 0.0219 - val_loss: 0.0016 - val_mae: 0.0220\n",
      "Epoch 91/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0016 - mae: 0.0219 - val_loss: 0.0016 - val_mae: 0.0218\n",
      "Epoch 92/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0016 - mae: 0.0219 - val_loss: 0.0016 - val_mae: 0.0221\n",
      "Epoch 93/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0016 - mae: 0.0219 - val_loss: 0.0016 - val_mae: 0.0225\n",
      "Epoch 94/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0016 - mae: 0.0219 - val_loss: 0.0016 - val_mae: 0.0222\n",
      "Epoch 95/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0016 - mae: 0.0219 - val_loss: 0.0016 - val_mae: 0.0220\n",
      "Epoch 96/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0016 - mae: 0.0219 - val_loss: 0.0016 - val_mae: 0.0222\n",
      "Epoch 97/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0016 - mae: 0.0219 - val_loss: 0.0016 - val_mae: 0.0223\n",
      "Epoch 98/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0016 - mae: 0.0219 - val_loss: 0.0016 - val_mae: 0.0223\n",
      "Epoch 99/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0016 - mae: 0.0219 - val_loss: 0.0016 - val_mae: 0.0222\n",
      "Epoch 100/100\n",
      "5250/5250 [==============================] - 9s 2ms/step - loss: 0.0016 - mae: 0.0218 - val_loss: 0.0016 - val_mae: 0.0222\n"
     ]
    }
   ],
   "source": [
    "# Creazione del modello Masked Autoencoder\n",
    "@keras.saving.register_keras_serializable('MLP')\n",
    "class MLP(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.input_layer = tf.keras.layers.InputLayer(input_shape=keypoints * (dim+1))\n",
    "        self.layer1 = tf.keras.layers.Dense(128, activation='relu')\n",
    "        self.layer2 = tf.keras.layers.Dense(256, activation='relu')\n",
    "        self.layer3 = tf.keras.layers.Dense(128, activation='relu')\n",
    "        self.layer4 = tf.keras.layers.Dense(keypoints * dim, activation='linear')\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Definisci i pesi dei layer in base alle dimensioni dell'input\n",
    "        super(MLP, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "  \n",
    "        x = tf.where(tf.math.is_nan(inputs), -1 * tf.ones_like(inputs), inputs)\n",
    "        x = self.input_layer(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        decoded = self.layer4(x)\n",
    "        return decoded\n",
    "\n",
    "def custom_mse_loss(y_true, y_pred):\n",
    "    mse_class = tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "    return mse_class\n",
    "\n",
    "\n",
    "autoencoder = MLP()\n",
    "autoencoder.build(input_shape=(1, keypoints * (dim+1)))\n",
    "autoencoder.summary()\n",
    "\n",
    "\n",
    "\n",
    "autoencoder.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), loss=custom_mse_loss, metrics=[\"mae\"])\n",
    "history = autoencoder.fit(X_train.squeeze(), y_train.squeeze(), batch_size=128, epochs=100, shuffle = True, validation_data=(X_val,y_val))\n",
    "autoencoder.save_weights(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mlp_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 48)]              0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            multiple                  6272      \n",
      "                                                                 \n",
      " dense_17 (Dense)            multiple                  33024     \n",
      "                                                                 \n",
      " dense_18 (Dense)            multiple                  32896     \n",
      "                                                                 \n",
      " dense_19 (Dense)            multiple                  4644      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 76836 (300.14 KB)\n",
      "Trainable params: 76836 (300.14 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "INFO:tensorflow:Assets written to: tmp/MLP_bio_h36m_cameraview_3D_absolute_onehot/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp/MLP_bio_h36m_cameraview_3D_absolute_onehot/assets\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()\n",
    "autoencoder.save_weights(model_name)\n",
    "autoencoder.save(model_name.replace(\".h5\",\"\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flk2",
   "language": "python",
   "name": "flk2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
